name: Scan EC2 Ranges

on:
  workflow_dispatch:

jobs:
  scan-ranges:
    runs-on: ubuntu-latest
    steps:
      - name: Checkout repository
        uses: actions/checkout@v3
        with:
          persist-credentials: true
          lfs: true

      - name: Setup Git LFS
        run: |
          git lfs install
          echo "*.json filter=lfs diff=lfs merge=lfs -text" > .gitattributes
          git add .gitattributes
          git commit -m "Setup Git LFS"
          git push || true

      - name: Adjust workspace permissions
        run: chmod -R 777 "${{ github.workspace }}"

      - name: Find and process unscanned ranges
        shell: bash
        run: |
          # Setup git configuration
          git config --local user.email "action@github.com"
          git config --local user.name "GitHub Action"

          # Function to split large JSON files
          split_json_if_needed() {
            local json_file="$1"
            local max_size=$((90 * 1024 * 1024)) # 90MB to be safe
            
            if [ $(stat -f%z "$json_file" 2>/dev/null || stat -c%s "$json_file") -gt $max_size ]; then
              echo "File exceeds 90MB, splitting into chunks..."
              
              # Create a directory for chunks
              local base_dir=$(dirname "$json_file")
              local chunks_dir="${base_dir}/chunks"
              mkdir -p "$chunks_dir"
              
              # Split the JSON array into smaller files
              python3 -c '
import json
import sys
import os

CHUNK_SIZE = 1000  # number of results per chunk

with open(sys.argv[1]) as f:
    data = json.load(f)

results = data["results"]
chunks = [results[i:i + CHUNK_SIZE] for i in range(0, len(results), CHUNK_SIZE)]

for i, chunk in enumerate(chunks):
    chunk_data = {"results": chunk}
    with open(f"{sys.argv[2]}/chunk_{i:03d}.json", "w") as f:
        json.dump(chunk_data, f)
' "$json_file" "$chunks_dir"

              # Remove the original large file
              rm "$json_file"
              
              # Create a manifest file
              echo "{\"type\":\"chunked\",\"chunks\":$(ls $chunks_dir | jq -R -s -c 'split("\n")[:-1]')}" > "${base_dir}/manifest.json"
            fi
          }

          # Process each range directory
          find ranges -type d -mindepth 1 -maxdepth 1 | while read -r dir; do
            echo "Processing directory: $dir"
            
            # Skip if already processed (check for manifest.json or certs.json)
            if [ -f "$dir/manifest.json" ] || [ -f "$dir/certs.json" ]; then
              echo "Skipping $dir - already processed"
              continue
            fi
            
            # Verify cidr.txt exists
            if [ ! -f "$dir/cidr.txt" ]; then
              echo "Error: cidr.txt not found in $dir"
              continue
            fi
            
            cidr=$(cat "$dir/cidr.txt")
            echo "Processing range: $cidr"
            
            # Create temporary directory
            tmp_dir="$dir/tmp"
            mkdir -p "$tmp_dir"
            
            # Run ZMap scan
            echo "Starting ZMap scan for $cidr"
            docker run --rm --network=host -v "${{ github.workspace }}":/data \
              sec32/zmap zmap -M tcp_synscan -p 443 -B 100K \
              "$cidr" -o "/data/$dir/tmp/open_ips.csv"
            
            if [ -s "$tmp_dir/open_ips.csv" ]; then
              echo "ZMap found open ports, running ZGrab2"
              docker run --rm --network=host -v "${{ github.workspace }}":/data -i \
                sec32/zgrab2 zgrab2 tls --port 443 \
                --input-file="/data/$dir/tmp/open_ips.csv" \
                --output-file="/data/$dir/certs.json"
              
              # Split large files if needed
              split_json_if_needed "$dir/certs.json"
              
              echo "Completed scanning range: $cidr"
            else
              echo "No open ports found for range: $cidr"
              echo '{"results":[]}' > "$dir/certs.json"
            fi
            
            # Cleanup temporary files
            rm -rf "$tmp_dir"
            
            # Commit results (either manifest.json + chunks or certs.json)
            git add "$dir"
            git commit -m "Add scan results for range $cidr"
            
            # Try to push, with retry logic
            for i in {1..3}; do
              if git push; then
                break
              else
                echo "Push failed, attempt $i of 3. Pulling and retrying..."
                git pull --rebase
                sleep 5
              fi
            done
          done
