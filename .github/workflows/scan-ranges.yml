name: Scan EC2 Range

on:
  workflow_dispatch:
    inputs:
      start_line:
        description: 'Start processing from line number (1-based)'
        required: true
        type: number
      batch_size:
        description: 'Number of ranges to process'
        required: true
        type: number
        default: 1

jobs:
  scan-range:
    runs-on: ubuntu-latest
    steps:
      - name: Checkout repository
        uses: actions/checkout@v3
        with:
          persist-credentials: true

      - name: Setup workspace
        run: |
          mkdir -p scan_results
          chmod -R 777 "${{ github.workspace }}"

      - name: Install dependencies
        run: |
          sudo apt-get update
          sudo apt-get install -y jq parallel

      - name: Process ranges
        run: |
          # Function to transform ZGrab2 output into a more manageable format
          transform_zgrab_output() {
            local input_file=$1
            local output_file=$2
            
            jq -c '
              def clean_cert_data:
                if type == "object" then
                  {
                    ip: .ip,
                    data: {
                      tls: {
                        status: .data.tls.status,
                        protocol: .data.tls.protocol,
                        result: {
                          handshake_log: {
                            server_hello: .data.tls.result.handshake_log.server_hello,
                            server_certificates: {
                              certificate: .data.tls.result.handshake_log.server_certificates.certificate,
                              validation: .data.tls.result.handshake_log.server_certificates.validation
                            }
                          }
                        }
                      }
                    }
                  }
                else
                  .
                end;

              {
                results: [inputs | clean_cert_data],
                scan_time: (now | strftime("%Y-%m-%dT%H:%M:%SZ"))
              }
            ' "$input_file" > "$output_file"
          }

          # Function to split large JSON results into smaller files
          split_results() {
            local input_file=$1
            local base_name=$2
            local chunk_size=500  # Reduced chunk size for better handling
            
            echo "Splitting results for $base_name"
            
            # Create directory for this range's results
            mkdir -p "scan_results/$base_name"
            
            # Count total results
            total_results=$(jq '.results | length' "$input_file")
            
            if [ "$total_results" -eq 0 ]; then
              echo "No results to split"
              echo '{"results":[],"scan_time":"'$(date -u +"%Y-%m-%dT%H:%M:%SZ")'"}' > "scan_results/$base_name/part_000.json"
              tar -czf "scan_results/${base_name}_part000.tar.gz" -C "scan_results/$base_name" "part_000.json"
              return
            fi
            
            # Split into chunks
            seq 0 $chunk_size $((total_results - 1)) | parallel -j4 bash -c '
              i=$0
              end=$((i + '$chunk_size'))
              part_num=$(printf "%03d" $((i / '$chunk_size')))
              
              echo "Creating part $part_num"
              jq -c "{
                results: .results[$i:$end],
                range: \"'$base_name'\",
                scan_time: .scan_time,
                part: \"$part_num\",
                total_parts: $(((('$total_results' + '$chunk_size' - 1) / '$chunk_size')))
              }" "'$input_file'" > "'scan_results/$base_name/part_$part_num.json'"
              
              tar -czf "'scan_results/${base_name}_part${part_num}.tar.gz'" \
                -C "'scan_results/$base_name'" "part_$part_num.json"
            '
            
            # Create manifest file
            echo "{
              \"range\": \"$base_name\",
              \"total_results\": $total_results,
              \"total_parts\": $(((total_results + chunk_size - 1) / chunk_size)),
              \"scan_time\": \"$(date -u +"%Y-%m-%dT%H:%M:%SZ")\"
            }" > "scan_results/${base_name}_manifest.json"
            
            # Cleanup temporary directory
            rm -rf "scan_results/$base_name"
          }

          # Process each range
          START_LINE=${{ inputs.start_line }}
          END_LINE=$((START_LINE + ${{ inputs.batch_size }} - 1))
          
          readarray -t RANGES < <(awk "NR >= $START_LINE && NR <= $END_LINE" ec2_ranges.txt)
          
          for cidr in "${RANGES[@]}"; do
            [ -z "$cidr" ] && continue
            
            echo "Processing range: $cidr"
            safe_name=$(echo "$cidr" | tr '/' '_')
            
            # Run ZMap scan with rate limiting and timeout
            timeout 30m docker run --rm --network=host -v "${{ github.workspace }}":/data \
              sec32/zmap zmap -M tcp_synscan -p 443 -B 100K \
              --cooldown-time=2 \
              "$cidr" -o "/data/tmp_open_ips.csv"
            
            if [ -s tmp_open_ips.csv ]; then
              echo "Found open ports, running ZGrab2..."
              # Run ZGrab2 with proper error handling
              if docker run --rm --network=host -v "${{ github.workspace }}":/data -i \
                sec32/zgrab2 zgrab2 tls --port 443 \
                --timeout 10s \
                --input-file=/data/tmp_open_ips.csv \
                --output-file=/data/tmp_certs.json; then
                
                # Transform and clean the output
                transform_zgrab_output "tmp_certs.json" "enriched_certs.json"
                
                # Split results if needed
                split_results "enriched_certs.json" "$safe_name"
              else
                echo "ZGrab2 scan failed for range: $cidr"
                continue
              fi
            else
              echo "No open ports found for range: $cidr"
              mkdir -p "scan_results/$safe_name"
              echo "{
                \"results\": [],
                \"range\": \"$cidr\",
                \"scan_time\": \"$(date -u +"%Y-%m-%dT%H:%M:%SZ")\"
              }" > "scan_results/${safe_name}_part000.json"
              tar -czf "scan_results/${safe_name}_part000.tar.gz" \
                -C "scan_results/$safe_name" "part000.json"
            fi
            
            # Cleanup temporary files
            rm -f tmp_open_ips.csv tmp_certs.json enriched_certs.json
          done
          
          # Commit results with retry logic
          git config --local user.email "action@github.com"
          git config --local user.name "GitHub Action"
          
          MAX_RETRIES=3
          RETRY_COUNT=0
          
          while [ $RETRY_COUNT -lt $MAX_RETRIES ]; do
            if git add scan_results/ && \
               git commit -m "Add scan results for ranges $START_LINE-$END_LINE" && \
               git push; then
              break
            else
              RETRY_COUNT=$((RETRY_COUNT + 1))
              if [ $RETRY_COUNT -lt $MAX_RETRIES ]; then
                echo "Push failed, retrying... (Attempt $RETRY_COUNT of $MAX_RETRIES)"
                git pull --rebase
              else
                echo "Failed to push after $MAX_RETRIES attempts"
                exit 1
              fi
            fi
          done
